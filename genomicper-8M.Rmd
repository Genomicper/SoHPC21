---
title: "Genomicper - 8M usecase"
author: " Aybuke Ozcelik, Irem Okur, Mario Antonioletti, Pau Navarro, Claudia Cabrera"
output: 
  html_document:
    toc: true
  md_document:
      variant: markdown_github
      toc: true
editor_options: 
  markdown: 
    wrap: 72
---

## Setup

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook which
allows code and text to be mixed. If you click on the `Knit` button
above RStudio will generate an html output directory.

Have taken a copy of the R sources of
[genomicper](https://github.com/Genomicper/genomicper). The routine
names (and file names) will have to be renamed but changes/improvements
can be made and compared with the original version The `source` command
can be used to load the alternative source files, e.g.
`source("Src/get_results_v2.R")` would load the `get_results_v2`
function version of `get_results`, note that each function in the file
also has to be renamed in order not to produce a name clash with the
version in the package. The renaming will take place as/when subroutines
are modified. New files should pass through `lintr` that makes files
comply with the [tidyverse style guide](https://style.tidyverse.org/).

```{r setup, echo=FALSE, message=FALSE, warning = FALSE}

library(genomicper)        # Package to be analysed
library(microbenchmark)    # Microbenchmark routines
library(profvis)           # Profile routines
library(lintr)             # Static R analyser
library(diffr)             # Source file comparison
library(here)              # Determine the root of where the files live
library(compiler)          # Library to compiler byte compile R functions
library(testthat)          # Testing routines.
library(ggplot2)           # Add plots
library(dplyr)             # Manipulate data frames

# Make sure the working directory is set to where this file lives.
setwd(paste0(here(), "/Workspaces/"))

```

```{r workflow}

# Remove all objects in the current environment
rm(list = ls())

# Sample workflow from the genomicper documentation

# Load files for analysis
data(demo, SNPsAnnotation)

# Read & format GWAS pvalues
all_data <- read_pvals(data_name = demo, snps_ann = SNPsAnnotation)

# Order data according to the genome
genome_results <- genome_order(all_data = all_data)

# Results from genome_order
ordered_alldata <- genome_results$ordered_alldata
gs_locs <- genome_results$gs_locs

# Create new environment to save variables (e.g. pathways, permutations):
gper.env <- new.env()

# Load more data
data(RHSA164843, RHSA446343, RHSA8876384, RHSA8964572, RHSA109582, RHSA1474244,
     envir = gper.env)

# Do we need to use environments?
data(RHSA164843, RHSA446343, RHSA8876384, RHSA8964572, RHSA109582, RHSA1474244)


# Map SNPs to pathways
paths_res <- read2_paths(ordered_alldata = ordered_alldata,
                         gs_locs = gs_locs,
                         sets_from = "workspace",
                         sets_prefix = "RHSA",
                         level = "snp",
                         envir = gper.env)

# Results from read2_paths:
pers_ids <- paths_res$per_ors
pathways <- paths_res$pathways

```

## Methodology

New versions of the original sources have been made and the file has
been renamed with a `_v2.R` as has the actual function name been
appended with a `_v2`. The idea would not be to create a `_v3`, `_v4`,
etc. unless you want to explicitly compare the performance with an
earlier version. I would say would be to assign the time consuming parts
to different individuals and then:

0.   run a static analyzer (lintr) on the files
1.  profile code (with small (10), big (30k), bigger (8M) data sets)
2.  identify expensive routines
3.  improve the code performance and compare with the original code
    (microbenchmarks)
4.  test the modified routine to check it gives the same results as
    the original code
5.  can the code performance be improved further, yes - go to step 1, no -
    continue to step 6.
6.  explore other ways of improving the performance:
    - convert R code to C
    - parallelise R code
    - parallelise C code
    - explore the use of memory to see if it can be improved
    - others?

## Baseline performance

### Load functions

Find out how long routines are taking to run. To start we need to load up the
new version of the files. If you change these you will have to load them up 
again. You should probably focus on the routines that are taking the longest 
time.

```{r read_alternative_files}

# Load all the alternative versions of the code (follow the *_v2.R pattern)
new_files <- list.files(path = "Src", pattern = "*_v2.R", full.names = TRUE)

# Loop round the files and source them to load them to the environment
for (file in new_files){
  source(file = file)
}

```

### read2_paths

Running a routine multiple times becomes a little bit annoying if output is 
produced every time. Profiling the function does not take much time so 
difficult to optimise. It appears that printing outputs does increase
the cost of the function.

```{r baseline_read2_paths}


# Perform a benchmark - read pvals
res <- microbenchmark(
  read_pvals(data_name = demo, snps_ann = SNPsAnnotation),
  read_pvals_v2(data_name = demo, snps_ann = SNPsAnnotation, verbose = TRUE),
  read_pvals_v2(data_name = demo, snps_ann = SNPsAnnotation),
  unit = "s",
  times = 20
)

```

Can view the results. The [boxplot](https://en.wikipedia.org/wiki/Box_plot) 
gives you an idea about the extent of the data while a 
[violin plot](https://en.wikipedia.org/wiki/Violin_plot) gives you an idea of 
the distribution of the data.

```{r view_read_pvals, message=FALSE}

# Boxplot of the results
boxplot(res, xlab = "read_pvals functions", 
        names = c("v1", "v2 (outputs)", "v2 (no outputs)"),
        col = c("red", "yellow", "yellow"))

# Another way of plotting
# ggplot2::autoplot(res)

# Using ggplot explicitly (more flexibility and control)
# Assumption: timer works to nanosecond accuracy
res %>% select(time, expr)         %>% 
        mutate(time = time / 10^9) %>% # Convert to seconds
        ggplot(aes(x = expr, y = time, fill = expr), alpha = 0.5) +
        geom_violin() +
        theme(legend.position = "none", 
              plot.title = element_text(hjust = 0.5)) +
        ylab("Time (s)") + xlab("Function version") +
        ggtitle("Comparsion of read_pvals") +
        scale_x_discrete(labels = c("v1", "v2 (output)", "v2 (no output)")) 

```

### read2_paths

This is reading from the workspace.

```{r baseline_read2_paths_2}

# Benchmark the routine
res2 <- microbenchmark(
        read2_paths(ordered_alldata = ordered_alldata,
                             gs_locs = gs_locs,
                             sets_from = "workspace",
                             sets_prefix = "RHSA",
                             level = "snp",
                             envir = gper.env),
        read2_paths_v2(ordered_alldata = ordered_alldata,
                             gs_locs = gs_locs,
                             sets_from = "workspace",
                             sets_prefix = "RHSA",
                             level = "snp",
                             envir = gper.env,
                             verbose = TRUE),
        read2_paths_v2(ordered_alldata = ordered_alldata,
                             gs_locs = gs_locs,
                             sets_from = "workspace",
                             sets_prefix = "RHSA",
                             level = "snp",
                             envir = gper.env),
        unit = "s",
        times = 20        
)


```

Plot the results:

```{r view_read2_paths}
# Boxplot of the results
boxplot(res2, xlab = "read2_paths functions", 
        names = c("v1", "v2 (outputs)", "v2 (no outputs)"),
        col = c("red", "yellow", "yellow"))

# Produce a violin plot of the output
res2 %>% select(time, expr)         %>% 
         mutate(time = time / 10^9) %>% # Convert to seconds
         ggplot(aes(x = expr, y = time, fill = expr), alpha = 0.5) +
         geom_violin() +
         theme(legend.position = "none", 
               plot.title = element_text(hjust = 0.5)) +
         ylab("Time (s)") + xlab("Function version") +
         ggtitle("Comparsion of read2_paths") +
         scale_x_discrete(labels = c("v1", "v2 (output)", "v2 (no output)")) 
```

Find out where the expensive part of the routine are:

```{r profile_read2_path}

profvis({
  read2_paths_v2(ordered_alldata = ordered_alldata,
                             gs_locs = gs_locs,
                             sets_from = "workspace",
                             sets_prefix = "RHSA",
                             level = "snp",
                             envir = gper.env,
                             verbose = TRUE)
})
```


## Testing

In modifying the code to improve the performance we need to ensure that
our improvements do not break the outputs. We can do this by ensuring
that the inputs and outputs produce the same results as the original
code. If there is any randomness involved we need to ensure that the
random seed is the same so that any sequence of random numbers is the
same for both routines.

```{r testing}


expect_equal(
  read_pvals(data_name = demo, snps_ann = SNPsAnnotation),
  read_pvals_v2(data_name = demo, snps_ann = SNPsAnnotation, verbose = TRUE)
)

expect_equal(
  read2_paths(ordered_alldata = ordered_alldata,
                         gs_locs = gs_locs,
                         sets_from = "workspace",
                         sets_prefix = "RHSA",
                         level = "snp",
                         envir = gper.env),
  read2_paths_v2(ordered_alldata = ordered_alldata,
                         gs_locs = gs_locs,
                         sets_from = "workspace",
                         sets_prefix = "RHSA",
                         level = "snp",
                         envir = gper.env, verbose = TRUE)
)
```

## Pofile

Profile an example piece of code:
