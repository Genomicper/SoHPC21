# Minutes for 14/12/21 

**DONM** (Date of next meeting): 2pm, 25/01/21 - no longer SoHPC

# Present

 * Mario Antonioletti [MA]
 * Pau Navarro [PN]
 * Claudia Cabrera [CC]
 * Silvia Shen [SC]

## Actions

### New and ongoing

- [X] **Pau** save a copy of the 30M data set on eddie.

```bash
[pnavarro@node2f23(eddie) genomicper]$ pwd  
/exports/igmm/eddie/genomicper  
[pnavarro@node2f23(eddie) genomicper]$ ls -lrt | tail -2  
-rw------- 1 pnavarro igmm_datastore_genomicper 1375802511 Dec 14 13:43 SNP_Table_Annotation_ALL.txt  
-rw------- 1 pnavarro igmm_datastore_genomicper  604293838 Dec 14 13:58 pvals_ALL.txt
[pnavarro@node2f23(eddie) genomicper]$ gzip -v9 pvals_ALL.txt
pvals_ALL.txt:   59.7% -- replaced with pvals_ALL.txt.gz
[pnavarro@node2f23(eddie) genomicper]$ gzip -v9 SNP_Table_Annotation_ALL.txt
SNP_Table_Annotation_ALL.txt:    78.9% -- replaced with SNP_Table_Annotation_ALL.txt.gz
[pnavarro@node2f23(eddie) genomicper]$
```

- [ ] **Mario** Do a systematic profiling with the data we have. 
  Can profile small segments of code (before it was crashing the R session in RStudio) problem is that I need to experiment and read on the R language to find improvements and have just not had time.
  
- [ ] **Mario** get Irem to confirm some of the profiling values.

- [ ] **All (Claudia to lead)** choose a framework for packages to use. Prioritise by memory and speed.

- [ ] **Mario** enumerate pros/cons of using data.table/tibbles
  * Interesting comparison: https://jozef.io/r917-fread-comparisons/
  * [stackoverflow](https://stackoverflow.com/questions/21435339/data-table-vs-dplyr-can-one-do-something-well-the-other-cant-or-does-poorly) states data.tables are faster especially for larger data sets.
  
- [ ] **Irem** put the parallelism in markdown.

- [ ] **Silvia** have a constructively critical look at genomicper.

- [ ] **Claudia** try running the 30M data set.

- [ ] **Mario** try running the 30M data set.
  Results from Microbenchmarks

  ```
                                                                 expr      min       lq       max neval    mean   median        uq
   read.table(file = infile, header = TRUE, stringsAsFactors = FALSE) 93.55874 95.22300  106.35863     599.07242 97.39790 102.82382
                          read_table(file = infile, col_types = cols) 56.47857 57.23174   71.40905     563.71495 65.56512  67.89029
                                                 fread(file = infile) 30.55904 33.09605 34.83237 35.52654  36.6708138.30937     5
   
  ```

  `read.table` and `read_table` produce `tibbles`while `fread`produces a `data.table`.

  ![Comparisons between various reading functions](../Workspaces/imgs/30M_read_table_vs_fread.png)

  A different set of runs comparing `fread` and `vroom`:

  ```
                                    expr       min        lq     mean   median       uq      max neval
   vroom(file = infile, col_types = cols)  8.660256  9.525121 11.82057 11.97287 14.35921 15.23637    10
                     fread(file = infile) 27.573730 27.976746 31.91760 31.26587 35.73686 38.04025    10
  ```

  ![vrom vs fread for reading the 30M dataset](../Workspaces/imgs/30M-vroom-vs-fread.png)

- [ ] **Pau**/**Silvia** find the best way of reading the 30M data set.

- [ ] **Claudia** Come up with a simple circos plot.

- [x] **Mario** send out actions for the next meeting.

### Completed
- [x] **Mario** find a time in December for our next meeting.
- [x] **Pau** see if access for Irem can be obtained on eddie.
- [x] **Silvia** pass on eddie notes to Irem.
- [x] **Claudia** annotate the 30M data set.

## Notes

Claudia made an annotated 30M data set available. The link she sent out will expire in two weeks. We shall all try to see if we an work with the data set. Silvia to look at using genomicper with a critical eye. Claudia to try and come up with a circus plot to use as a logo for the GitHub org.
